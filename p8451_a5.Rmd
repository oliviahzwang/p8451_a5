---
title: "P8451 Machine Learning in Public Health - Assignment 5"
output: word_document
date: "2023-2-21"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In preparation for all the analyses below, we will load the following libraries:

```{r}
library(caret)
library(tidyverse)
library(dplyr)
library(stats)
library(factoextra)
library(cluster)
library(ggpubr)
library(pscl)
```

# Part 0: Data Preprocessing

We will begin by importing the drug use and personality trait survey data using the `read_csv` function. Next, we will clean the data by first applying the `clean_names` function, then applying the `mutate` function to rename the ID variable and to convert the `alc_consumption` variable from a character to a 2-level factor variable. The following 8 features are included in this data set: 

* `alc_consumption` 
* `neurotocism_score` 
* `extroversion_score`
* `openness_score`
* `agreeableness_score` 
* `conscientiousness_score` 
* `impulsiveness_score` 
* `sens_seeking_score` 

Finally, we remove entries with NA using `na.omit`, any duplicate ID entries using the `distinct` function, and finally drop the unwanted ID entry using `select`. 

```{r}
alcohol_use = read_csv("./alcohol_use.csv") %>% 
  janitor::clean_names() %>% 
  mutate(id = x1, 
         alc_consumption = factor(alc_consumption, 
                                  labels = c("Current User", "Not Current User"))) %>% 
  na.omit() %>% 
  distinct(id, .keep_all = TRUE) %>% 
  select(alc_consumption, neurotocism_score, extroversion_score, openness_score,
         agreeableness_score, conscientiousness_score, impulsiveness_score, 
         sens_seeking_score)
```

## Feature Selection: Identifying and Removing Correlated Predictors

Many machine learning algorithms are unable to differentiate between highly correlated features. As such, we want to identify highly correlated features that present the same mathematical information and subsequently remove them, to avoid introducing error in our approach. 

To complete this feature selection process, we will first select only the numeric variables in our `alcohol_use` data set, since correlations can only be assessed with numeric variables. We will then apply the `cor` function that will calculate correlations. These calculated correlations will then be fed into the `findCorrelation` function with a cutoff of __0.4__. The features that correlated at 0.4 and above will be stored in a new objected labeled as `high_correlations`.

```{r}
alcohol_use_numeric = alcohol_use %>% 
  select(where(is.numeric)) 

correlations = cor(alcohol_use_numeric, use = "complete.obs")

high_correlations = findCorrelation(correlations, cutoff = 0.4)
```

The `high_correlations` object contains the indexes of 2 correlated predictors: 7 and 2. These correspond to the `extroversion_score` and `sens_seeking_score` features. In the code chunk below, will remove these highly correlated features. 

```{r}
alcohol_use_tidy = alcohol_use_numeric[ , -high_correlations] 
```

## Centering and Scaling

Below, we center and scale these data. In general, it is always good practice to do so! 

```{r}
preprocess_setup <- preProcess(alcohol_use_tidy, method = c("center", "scale"))
```

## Partitioning Data

For the purposes of this analysis, we will partition the data into training and testing using a 70/30 split. This process involves applying the `createDataPartition` function to generate a set of training and testing data with equal proportion of individual with the outcome of interest, i.e., `alc_consumption`. The new object `train_index` contains all the indexes of the rows in the original data set contained in the 70% split. The rows indexed to be in the 70% is assigned to a new training data set, and the remaining 30% is assigned to a new testing data set. 

```{r}
alcohol_use_tidy$alc_consumption = alcohol_use$alc_consumption

train_index = createDataPartition(alcohol_use_tidy$alc_consumption, p = 0.7, list = FALSE)

alcohol_use_train <- alcohol_use_tidy[train_index,]
alcohol_use_test <- alcohol_use_tidy[-train_index,]
```

# Part I: Creating Three Different Models

For the purposes of this analysis, we will create and compare the following models: 

1. Elastic Net Model that chooses alpha and lambda via cross-validation using all features
1. Traditional Logistic Regression Model using all features
1. Lasso Model using all features

## 1.1 Model 1: Elastic Net with All Features

In the code chunk below, we will use the `trainControl` function to set our validation method. For the purposes of this analysis, we will use the 10-fold cross validation method.

```{r}
control.settings = 
  trainControl(method = "cv", number = 10)
```

These control settings can now be applied within the `train` function, which will be used to implement our algorithms. We also apply the `tuneLength` function to set the number of combinations of different values of alpha and lambda to compare. In this analysis, we will set `tunelength` to 10. Finally, we can apply the `coef` function to model the coefficients at the lambda and alpha values that minimize the RMSE. 

```{r}
set.seed(123)
alcohol_use_model_1 = 
  train(alc_consumption ~ neurotocism_score + openness_score + agreeableness_score + 
        conscientiousness_score + impulsiveness_score, 
        data = alcohol_use_train, 
        method = "glmnet", 
        preProc = c("center", "scale"), 
        trControl = control.settings, 
        tuneLength = 10)

alcohol_use_model_1$bestTune %>% 
  knitr::kable()

coef(alcohol_use_model_1$finalModel, alcohol_use_model_1$bestTune$lambda)
```

Based on the output above, the alpha and lambda values that minimize the RMSE are 0.4 and 0.26, respectively. 

## 1.2 Model 2: Traditional Logistic Regression Model with All Features

Below we construct a logistic regression model using the `glm` function, with alcohol consumption as the outcome of interest, and neuroticism, openness, agreeableness, conscientiousness, and impulsiveness scores as the independent variables of interest. To do so, we apply the `glm` function. To assess how the model fits the data, we can compute the McFadden's R^2. 

```{r}
alcohol_use_model_2 = 
  glm(alc_consumption ~ neurotocism_score + openness_score + agreeableness_score + 
      conscientiousness_score + impulsiveness_score, 
      data = alcohol_use_train, 
      family = binomial())

pscl::pR2(alcohol_use_model_2)
```
The McFadden's R^2 takes on a value of 0.34. Since 0.34 lies between 0.2 and 0.4, there is evidence of very good model fit. 

## 1.3 Model 3: Lasso Model with All Features

To generate a lasso model, we will set alpha equal to 1. We will apply cross validation methods to select the value of lambda that minimizes the RMSE. This process involves using a tuning grid for lambda, and the parameters of the grid search are determined by first running a rough grid search, then narrowing down the range of values to yield more precise values. 

```{r}
lambda = seq(0, 1, length = 20)
lambda_grid = expand.grid(alpha = 1, lambda = lambda)

set.seed(123)
alcohol_use_model_3 = 
 train(alc_consumption ~ neurotocism_score + openness_score + agreeableness_score + 
         conscientiousness_score + impulsiveness_score, 
       data = alcohol_use_train, 
       method = "glmnet", 
       preProc = c("center", "scale"), 
       trControl = control.settings, 
       tuneGrid = lambda_grid)

alcohol_use_model_3$bestTune
```

Based on the output above, the lambda value that minimizes the RMSE alongside the alpha value of 1 is 0.21.

## 1.4 Choosing a Final Model 

To determine which of the three models to choose for the analysis, we will determine which model yields the highest accuracy of predictions. To do so, we will first use the training data set to predict the outcome of interest with each model, and compare the predictions to the observed data.

```{r}
train_outcome_model_1 = predict(alcohol_use_model_1, alcohol_use)
sum(train_outcome_model_1 == alcohol_use$alc_consumption) / length(train_outcome_model_1)

train_outcome_model_2 = predict(alcohol_use_model_2, alcohol_use)
sum(ifelse(train_outcome_model_2 < 0.5, "Current User", "Not Current User") == alcohol_use$alc_consumption) / length(train_outcome_model_2)

train_outcome_model_3 = predict(alcohol_use_model_3, alcohol_use)
sum(train_outcome_model_3 == alcohol_use$alc_consumption) / length(train_outcome_model_3)
```
Both the Elastic Net and Lasso models yield 85.25% accuracy, whereas the traditional logistic regression model yields 84.24% accuracy. Given the same accuracy, we can proceed with the Elastic Net model for the final analysis, since it is an overall more powerful model compared to the Lasso. 

# Part II: Applying the Final Model to Testing Data

Below we apply the Elastic Net model generated in Part I within the testing data by using the `predict` function.

```{r}
test_outcome_final = predict(alcohol_use_model_1, alcohol_use_test)

confusionMatrix(test_outcome_final, alcohol_use_test$alc_consumption, positive = "Current User")
```
The accuracy for the Elastic Net model is 0.8478, and the Kappa value is 0.688. The 95% confidence interval associated with the accuracy is 0.8155 to 0.8764. The sensitivity of this model is 1.000, and the specificity is 0.6742. 

# Part III: A Research Application of this Analysis

This analysis using the predictive model generated above can provide information regarding key personality traits that are heavily predictive of alcohol consumption. In future analyses, researchers can potentially forego the completion of extensive behavioral testing and instead use indicators of key personality traits to predict an individual's probability of being or becoming an alcohol user. Additionally, as usage of various substances in tandem to alcohol such as smoking and cannabis is common, this analysis may also be used to predict an individual's usage of other such substances. 




